rm: 无法删除".": 是一个目录
rm: 无法删除"..": 是一个目录
rm: 无法删除".git": 是一个目录
~ ~/dcu/qcu
~/configure ~ ~/dcu/qcu
HOME:/public/home/zhangxin/configure
~ ~/dcu/qcu
~/dcu/qcu
Currently Loaded Modulefiles:
  1) compiler/devtoolset/7.3.1   3) compiler/gcc/7.3.1
  2) compiler/dtk-23.04          4) hpcx/gcc-7.3.1
/public/sugon/software/compiler/dtk-23.04 ~/dcu/qcu
/public/sugon/software/compiler/dtk-23.04/cuda /public/sugon/software/compiler/dtk-23.04 ~/dcu/qcu
/public/sugon/software/compiler/dtk-23.04 ~/dcu/qcu
~/dcu/qcu
-- The C compiler identification is Clang 14.0.0
-- The CXX compiler identification is Clang 14.0.0
-- The CUDA compiler identification is NVIDIA 10.2.89
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /public/sugon/software/compiler/dtk-23.04/bin/hipcc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /public/sugon/software/compiler/dtk-23.04/bin/hipcc - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /public/sugon/software/compiler/dtk-23.04/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Found MPI_C: /public/sugon/software/mpi/hpcx/hpcx-v2.4.1.0-gcc/ompi/lib/libmpi.so (found version "3.1") 
-- Found MPI_CXX: /public/sugon/software/mpi/hpcx/hpcx-v2.4.1.0-gcc/ompi/lib/libmpi.so (found version "3.1") 
-- Found MPI: TRUE (found version "3.1")  
-- Configuring done (16.5s)
CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "qcu".
This warning is for project developers.  Use -Wno-dev to suppress it.

CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "qcu".
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done (0.0s)
-- Build files have been written to: /public/home/zhangxin/dcu/qcu
[  3%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/test_overlap_bistabcg.cu.o
[  7%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/mpi_clover_bistabcg.cu.o
[ 14%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/mpi_overlap_bistabcg.cu.o
[ 14%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/mpi_overlap_dslash.cu.o
[ 17%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/mpi_overlap_multgrid.cu.o
[ 25%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/test_clover_multgrid.cu.o
[ 25%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/mpi_clover_multgrid.cu.o
[ 32%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/mpi_wilson_dslash.cu.o
[ 35%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/mpi_wilson_multgrid.cu.o
[ 35%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/test_wilson_bistabcg.cu.o
[ 42%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/mpi_wilson_bistabcg.cu.o
[ 42%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/test_clover_bistabcg.cu.o
[ 50%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/test_overlap_dslash.cu.o
[ 50%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/clover_bistabcg.cu.o
[ 53%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/test_overlap_multgrid.cu.o
[ 57%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/test_wilson_multgrid.cu.o
[ 64%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/overlap_dslash.cu.o
[ 64%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/overlap_bistabcg.cu.o
[ 71%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/clover_dslash.cu.o
[ 82%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/overlap_multgrid.cu.o
[ 85%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/test_wilson_dslash.cu.o
[ 85%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/wilson_dslash.cu.o
[ 85%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/wilson_multgrid.cu.o
[ 85%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/wilson_bistabcg.cu.o
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
[ 89%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/mpi_clover_dslash.cu.o
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
[ 92%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/test_clover_dslash.cu.o
[ 96%] Building CUDA object CMakeFiles/qcu.dir/src/cuda/clover_multgrid.cu.o
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
Warning: -forward-unknown-to-host-compiler Not Support
Warning: nvcc current only support gfx906 and gfx926 arch. All architecture parameters will be replaced by gfx906 arch.
[100%] Linking CUDA shared library libqcu.so
[100%] Built target qcu
~/dcu/qcu/test ~/dcu/qcu
[dcu004:25198] pml_ucx.c:285  Error: UCP worker does not support MPI_THREAD_MULTIPLE
[dcu004:25196] pml_ucx.c:285  Error: UCP worker does not support MPI_THREAD_MULTIPLE
[dcu004:25197] pml_ucx.c:285  Error: UCP worker does not support MPI_THREAD_MULTIPLE
[dcu004:25195] pml_ucx.c:285  Error: UCP worker does not support MPI_THREAD_MULTIPLE
Disabling GPU-Direct RDMA access
Enabling peer-to-peer copy engine and direct load/store access
Peer-to-peer enabled for rank   3 (gpu=3) with neighbor   1 (gpu=1) dir=0, dim=0, access rank = (  2)
Peer-to-peer enabled for rank   3 (gpu=3) with neighbor   2 (gpu=2) dir=0, dim=3, access rank = (  2)
Peer-to-peer enabled for rank   3 (gpu=3) with neighbor   1 (gpu=1) dir=1, dim=0, access rank = (  2)
Peer-to-peer enabled for rank   1 (gpu=1) with neighbor   3 (gpu=3) dir=0, dim=0, access rank = (  2)
Peer-to-peer enabled for rank   1 (gpu=1) with neighbor   0 (gpu=0) dir=0, dim=3, access rank = (  2)
Peer-to-peer enabled for rank   1 (gpu=1) with neighbor   3 (gpu=3) dir=1, dim=0, access rank = (  2)
Peer-to-peer enabled for rank   1 (gpu=1) with neighbor   0 (gpu=0) dir=1, dim=3, access rank = (  2)
Peer-to-peer enabled for rank   0 (gpu=0) with neighbor   2 (gpu=2) dir=0, dim=0, access rank = (  2)
Peer-to-peer enabled for rank   2 (gpu=2) with neighbor   0 (gpu=0) dir=0, dim=0, access rank = (  2)
Peer-to-peer enabled for rank   2 (gpu=2) with neighbor   3 (gpu=3) dir=0, dim=3, access rank = (  2)
Peer-to-peer enabled for rank   2 (gpu=2) with neighbor   0 (gpu=0) dir=1, dim=0, access rank = (  2)
Peer-to-peer enabled for rank   2 (gpu=2) with neighbor   3 (gpu=3) dir=1, dim=3, access rank = (  2)
Peer-to-peer enabled for rank   3 (gpu=3) with neighbor   2 (gpu=2) dir=1, dim=3, access rank = (  2)
Peer-to-peer enabled for rank   0 (gpu=0) with neighbor   1 (gpu=1) dir=0, dim=3, access rank = (  2)
Peer-to-peer enabled for rank   0 (gpu=0) with neighbor   2 (gpu=2) dir=1, dim=0, access rank = (  2)
Peer-to-peer enabled for rank   0 (gpu=0) with neighbor   1 (gpu=1) dir=1, dim=3, access rank = (  2)
QUDA 1.1.0 (git 1.1.0-b869d61-dirty-gfx906)
*** HIP BACKEND ***
HIP Driver version = 50400000
HIP Runtime version = 50400000
Found device 0: Z100
Found device 1: Z100
Found device 2: Z100
Found device 3: Z100
Found device 4: Z100
Found device 5: Z100
Found device 6: Z100
Found device 7: Z100
Using device 0: Z100
WARNING: Data reordering done on GPU (set with QUDA_REORDER_LOCATION=GPU/CPU)
Loaded 153 sets of cached parameters from .cache/tunecache.tsv
Loaded 153 sets of cached parameters from .cache/tunecache.tsv
WARNING: Using device memory pool allocator
WARNING: Using pinned memory pool allocator
===============round  0 ======================
===============round  0 ======================
===============round  0 ======================
hipblasCreated successfully
===============round  0 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.4811266470060218 sec
Quda dslash: 0.49453412200091407 sec
Quda dslash: 0.47612333700817544 sec
Quda dslash: 0.4356011740019312 sec
test wilson dslash total time: (without malloc free memcpy) : 0.077949384 sec
test wilson dslash total time: (without malloc free memcpy) : 0.073497157 sec
test wilson dslash total time: (without malloc free memcpy) : 0.052677605 sec
test wilson dslash total time: (without malloc free memcpy) : 0.011709672 sec
test wilson dslash total time: (without malloc free memcpy) : 0.056521616 sec
test wilson dslash total time: (without malloc free memcpy) : 0.074312153 sec
QCU dslash: 0.6714980569959152 sec
QCU dslash: 0.6714828910044162 sec
test wilson dslash total time: (without malloc free memcpy) : 0.024335919 sec
QCU dslash: 0.6715047369943932 sec
test wilson dslash total time: (without malloc free memcpy) : 0.011202933 sec
QCU dslash: 0.6676008020003792 sec
quda difference:  2.7655670883158336e-16
===============round  1 ======================
quda difference:  2.7658441899771356e-16
===============round  1 ======================
quda difference:  2.7649190973307657e-16
===============round  1 ======================
quda difference:  2.765501525705186e-16
===============round  1 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.09961623599519953 sec
Quda dslash: 0.11077539500547573 sec
Quda dslash: 0.09625250499811955 sec
Quda dslash: 0.07999139200546779 sec
test wilson dslash total time: (without malloc free memcpy) : 0.066775759 sec
test wilson dslash total time: (without malloc free memcpy) : 0.055640559 sec
test wilson dslash total time: (without malloc free memcpy) : 0.026231490 sec
test wilson dslash total time: (without malloc free memcpy) : 0.008340021 sec
test wilson dslash total time: (without malloc free memcpy) : 0.058763529 sec
test wilson dslash total time: (without malloc free memcpy) : 0.078052992 sec
test wilson dslash total time: (without malloc free memcpy) : 0.021505738 sec
QCU dslash: 0.7187994010018883 sec
QCU dslash: 0.7188092889991822 sec
QCU dslash: 0.7186820009956136 sec
test wilson dslash total time: (without malloc free memcpy) : 0.012369835 sec
QCU dslash: 0.7146489870065125 sec
quda difference:  2.7654573618487885e-16
===============round  2 ======================
quda difference:  2.764687656001583e-16
===============round  2 ======================
quda difference:  2.764093942771988e-16
===============round  2 ======================
quda difference:  2.7650431458427826e-16
===============round  2 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.12056264599959832 sec
Quda dslash: 0.11240601800091099 sec
Quda dslash: 0.07815607500378974 sec
Quda dslash: 0.09534739500668366 sec
test wilson dslash total time: (without malloc free memcpy) : 0.064240426 sec
test wilson dslash total time: (without malloc free memcpy) : 0.080349622 sec
test wilson dslash total time: (without malloc free memcpy) : 0.055499983 sec
test wilson dslash total time: (without malloc free memcpy) : 0.008640590 sec
test wilson dslash total time: (without malloc free memcpy) : 0.066620710 sec
test wilson dslash total time: (without malloc free memcpy) : 0.031995765 sec
QCU dslash: 0.7141551759996219 sec
QCU dslash: 0.7141475039970828 sec
test wilson dslash total time: (without malloc free memcpy) : 0.026133996 sec
QCU dslash: 0.7142256229999475 sec
test wilson dslash total time: (without malloc free memcpy) : 0.013402305 sec
QCU dslash: 0.7100693749962375 sec
quda difference:  2.76635783505676e-16
===============round  3 ======================
quda difference:  2.764308837205836e-16
===============round  3 ======================
quda difference:  2.7649048628648954e-16
===============round  3 ======================
quda difference:  2.765383990650518e-16
===============round  3 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.2068772530037677 sec
Quda dslash: 0.2124322210001992 sec
Quda dslash: 0.17235074000200257 sec
Quda dslash: 0.1614511230000062 sec
test wilson dslash total time: (without malloc free memcpy) : 0.073568850 sec
test wilson dslash total time: (without malloc free memcpy) : 0.070689821 sec
test wilson dslash total time: (without malloc free memcpy) : 0.029539035 sec
test wilson dslash total time: (without malloc free memcpy) : 0.008237325 sec
test wilson dslash total time: (without malloc free memcpy) : 0.060605676 sec
test wilson dslash total time: (without malloc free memcpy) : 0.055928345 sec
test wilson dslash total time: (without malloc free memcpy) : 0.020520490 sec
QCU dslash: 0.649523850006517 sec
QCU dslash: 0.6495594950101804 sec
QCU dslash: 0.6493642319983337 sec
test wilson dslash total time: (without malloc free memcpy) : 0.013294951 sec
QCU dslash: 0.6452920989977429 sec
quda difference:  2.765832716346255e-16
quda difference:  2.7658096099068e-16
===============round  4 ======================
===============round  4 ======================
quda difference:  2.7658221204971213e-16
===============round  4 ======================
quda difference:  2.7656353372204337e-16
===============round  4 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.13251640601083636 sec
Quda dslash: 0.13216988899512216 sec
Quda dslash: 0.12507268799527083 sec
Quda dslash: 0.10242544001084752 sec
test wilson dslash total time: (without malloc free memcpy) : 0.064231468 sec
test wilson dslash total time: (without malloc free memcpy) : 0.064199970 sec
test wilson dslash total time: (without malloc free memcpy) : 0.030759229 sec
test wilson dslash total time: (without malloc free memcpy) : 0.008439101 sec
test wilson dslash total time: (without malloc free memcpy) : 0.093692748 sec
QCU dslash: 0.7661790330021176 sec
test wilson dslash total time: (without malloc free memcpy) : 0.096095739 sec
QCU dslash: 0.7661787329998333 sec
test wilson dslash total time: (without malloc free memcpy) : 0.061432176 sec
QCU dslash: 0.7662555790011538 sec
test wilson dslash total time: (without malloc free memcpy) : 0.025238393 sec
QCU dslash: 0.762011465994874 sec
quda difference:  2.7645498268181176e-16
quda difference:  2.7656186563157004e-16
===============round  5 ======================
===============round  5 ======================
quda difference:  2.7660100830201335e-16
quda difference:  2.765627898322083e-16
===============round  5 ======================
===============round  5 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.17844966499251314 sec
Quda dslash: 0.1771629829891026 sec
Quda dslash: 0.14023737699608319 sec
Quda dslash: 0.14318204199662432 sec
test wilson dslash total time: (without malloc free memcpy) : 0.064411885 sec
test wilson dslash total time: (without malloc free memcpy) : 0.067305264 sec
test wilson dslash total time: (without malloc free memcpy) : 0.032978596 sec
test wilson dslash total time: (without malloc free memcpy) : 0.007861736 sec
test wilson dslash total time: (without malloc free memcpy) : 0.064044207 sec
test wilson dslash total time: (without malloc free memcpy) : 0.068732764 sec
QCU dslash: 0.7664150769996922 sec
QCU dslash: 0.7664149789925432 sec
test wilson dslash total time: (without malloc free memcpy) : 0.033380840 sec
QCU dslash: 0.7663645199936582 sec
test wilson dslash total time: (without malloc free memcpy) : 0.014403861 sec
QCU dslash: 0.7668713750026654 sec
quda difference:  2.765929888259535e-16
quda difference:  2.7654259754601685e-16
===============round  6 ======================
===============round  6 ======================
quda difference:  2.764224702503258e-16
===============round  6 ======================
quda difference:  2.7659477798693154e-16
===============round  6 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.15124958899104968 sec
Quda dslash: 0.1418904960009968 sec
Quda dslash: 0.13629902100365143 sec
Quda dslash: 0.09288084800937213 sec
test wilson dslash total time: (without malloc free memcpy) : 0.066839047 sec
test wilson dslash total time: (without malloc free memcpy) : 0.062841245 sec
test wilson dslash total time: (without malloc free memcpy) : 0.011562729 sec
test wilson dslash total time: (without malloc free memcpy) : 0.031298387 sec
test wilson dslash total time: (without malloc free memcpy) : 0.069619713 sec
test wilson dslash total time: (without malloc free memcpy) : 0.067340597 sec
QCU dslash: 0.8380827559885802 sec
QCU dslash: 0.8380884920043172 sec
test wilson dslash total time: (without malloc free memcpy) : 0.030753720 sec
QCU dslash: 0.8379854899976635 sec
test wilson dslash total time: (without malloc free memcpy) : 0.015211893 sec
QCU dslash: 0.8386570179864066 sec
quda difference:  2.7648126208379677e-16
quda difference:  2.7653681260203653e-16
===============round  7 ======================
===============round  7 ======================
quda difference:  2.7647937067872894e-16
===============round  7 ======================
quda difference:  2.764983132252389e-16
===============round  7 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.131725234008627 sec
Quda dslash: 0.14617206899856683 sec
Quda dslash: 0.08197108100284822 sec
Quda dslash: 0.11047189999953844 sec
test wilson dslash total time: (without malloc free memcpy) : 0.067615349 sec
test wilson dslash total time: (without malloc free memcpy) : 0.065797174 sec
test wilson dslash total time: (without malloc free memcpy) : 0.011660135 sec
test wilson dslash total time: (without malloc free memcpy) : 0.033862106 sec
test wilson dslash total time: (without malloc free memcpy) : 0.065245744 sec
test wilson dslash total time: (without malloc free memcpy) : 0.066255037 sec
QCU dslash: 0.8884467450116063 sec
test wilson dslash total time: (without malloc free memcpy) : 0.007974129 sec
QCU dslash: 0.8884223150089383 sec
QCU dslash: 0.8884472999925492 sec
test wilson dslash total time: (without malloc free memcpy) : 0.022993912 sec
QCU dslash: 0.8887516139948275 sec
quda difference:  2.7658724849164995e-16
===============round  8 ======================
quda difference:  2.7655862877963544e-16
===============round  8 ======================
quda difference:  2.7651178936595616e-16
===============round  8 ======================
quda difference:  2.764231527886283e-16
===============round  8 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.12613297101052012 sec
Quda dslash: 0.1385822120064404 sec
Quda dslash: 0.08914558100514114 sec
Quda dslash: 0.10830928399809636 sec
test wilson dslash total time: (without malloc free memcpy) : 0.066359660 sec
test wilson dslash total time: (without malloc free memcpy) : 0.062493835 sec
test wilson dslash total time: (without malloc free memcpy) : 0.027183033 sec
test wilson dslash total time: (without malloc free memcpy) : 0.008664670 sec
test wilson dslash total time: (without malloc free memcpy) : 0.081472023 sec
test wilson dslash total time: (without malloc free memcpy) : 0.088529442 sec
QCU dslash: 0.9462660370045342 sec
QCU dslash: 0.946260076991166 sec
test wilson dslash total time: (without malloc free memcpy) : 0.037175064 sec
QCU dslash: 0.9461602609953843 sec
test wilson dslash total time: (without malloc free memcpy) : 0.011508452 sec
QCU dslash: 0.9467302080010995 sec
quda difference:  2.7654774870714793e-16
quda difference:  2.7657673835466783e-16
===============round  9 ======================
===============round  9 ======================
quda difference:  2.765271501274444e-16
===============round  9 ======================
quda difference:  2.765175805805311e-16
===============round  9 ======================
Creating Gaussian distributed Lie group field with sigma = 1.000000e-01
Quda dslash: 0.09686193900415674 sec
Quda dslash: 0.10643950299709104 sec
Quda dslash: 0.07583903800696135 sec
Quda dslash: 0.07315190500230528 sec
test wilson dslash total time: (without malloc free memcpy) : 0.067843712 sec
test wilson dslash total time: (without malloc free memcpy) : 0.066934649 sec
test wilson dslash total time: (without malloc free memcpy) : 0.025053025 sec
test wilson dslash total time: (without malloc free memcpy) : 0.008584676 sec
test wilson dslash total time: (without malloc free memcpy) : 0.006874848 sec
test wilson dslash total time: (without malloc free memcpy) : 0.074587369 sec
QCU dslash: 0.996947175997775 sec
test wilson dslash total time: (without malloc free memcpy) : 0.078293170 sec
QCU dslash: 0.996949529988342 sec
QCU dslash: 0.9967977970081847 sec
test wilson dslash total time: (without malloc free memcpy) : 0.030741615 sec
QCU dslash: 0.9972939519939246 sec
quda difference:  2.765653068843297e-16
quda difference:  2.7653077788231965e-16
quda difference:  2.7651814294123613e-16
quda difference:  2.76586079697914e-16
WARNING: Environment variable QUDA_PROFILE_OUTPUT_BASE not set; writing to profile.tsv and profile_async.tsv
Saving 20 sets of cached parameters to .cache/profile_0.tsv
Saving 0 sets of cached profiles to .cache/profile_async_0.tsv

               initQuda Total time =    28.959 secs
                     init     =    28.959 secs (100.000%),	 with        2 calls at 1.448e+07 us per call
        total accounted       =    28.959 secs (100.000%)
        total missing         =     0.000 secs (  0.000%)

          loadGaugeQuda Total time =     1.431 secs
                 download     =     0.849 secs ( 59.308%),	 with       20 calls at 4.243e+04 us per call
                   upload     =     0.109 secs (  7.601%),	 with       10 calls at 1.088e+04 us per call
                     init     =     0.120 secs (  8.417%),	 with       20 calls at 6.022e+03 us per call
                  compute     =     0.352 secs ( 24.606%),	 with       20 calls at 1.760e+04 us per call
                     free     =     0.000 secs (  0.025%),	 with       20 calls at 1.795e+01 us per call
        total accounted       =     1.430 secs ( 99.956%)
        total missing         =     0.001 secs (  0.044%)

             dslashQuda Total time =     0.949 secs
                 download     =     0.015 secs (  1.537%),	 with       20 calls at 7.295e+02 us per call
                   upload     =     0.001 secs (  0.114%),	 with       20 calls at 5.415e+01 us per call
                     init     =     0.002 secs (  0.167%),	 with       20 calls at 7.940e+01 us per call
                  compute     =     0.932 secs ( 98.145%),	 with       20 calls at 4.658e+04 us per call
                     free     =     0.000 secs (  0.021%),	 with       20 calls at 1.005e+01 us per call
        total accounted       =     0.949 secs ( 99.984%)
        total missing         =     0.000 secs (  0.016%)

                endQuda Total time =     0.156 secs

       initQuda-endQuda Total time =    41.296 secs

                   QUDA Total time =    31.915 secs
                 download     =     0.863 secs (  2.705%),	 with       40 calls at 2.158e+04 us per call
                   upload     =     0.110 secs (  0.344%),	 with       30 calls at 3.662e+03 us per call
                     init     =    29.081 secs ( 91.120%),	 with       42 calls at 6.924e+05 us per call
                  compute     =     1.704 secs (  5.340%),	 with       50 calls at 3.408e+04 us per call
                     free     =     0.001 secs (  0.002%),	 with       40 calls at 1.393e+01 us per call
        total accounted       =    31.758 secs ( 99.511%)
        total missing         =     0.156 secs (  0.489%)

Device memory used = 701.2 MiB
Pinned device memory used = 32.0 MiB
Managed memory used = 0.0 MiB
Page-locked host memory used = 30.0 MiB
Total host memory used >= 41.3 MiB

~/dcu/qcu
